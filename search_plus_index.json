{"./":{"url":"./","title":"前言","keywords":"","body":"Apache Skywalking Handbook 本手册将指导你如何使用Skywalking构建APM系统。 通过此手册你可以了解到所有有关 SkyWalking 的架构, 如何部署并使用 SkyWalking, 以及如何基于 SkyWalking 进行开发。 注意⚠️：基于 Skywalking 最新 8.1.0 版本 在线浏览地址：https://skywalking-handbook.netlify.com/ Github地址：https://github.com/JaredTan95/skywalking-handbook 目标读者 本文档适用于以下读者： 对追踪系统感兴趣 打算在公司使用 Skywalking 想了解追踪系统以及 Skywalking 内部机制 图片 - PDF 书籍封面——By Allen Wang 贡献者 感谢此书的贡献者。 联系作者 图片 - Jared Tan Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"concepts/overview.html":{"url":"concepts/overview.html","title":"概述","keywords":"","body":"观察分布式服务 服务化的发展，以及容器化编排、微服务架构、Service Mesh 等各项技术的持续进化，为分布式服务化提供了技术层面的支持。 但是，仅仅构建微服务是不够的，对于一套完整的技术体系而言，除了开发，还需要运维给予强力支持。 随着微服务架构的持续演进，应用和服务数量不断增加，调用关系越来越复杂。所以，从运维的角度来看，首要任务便是保持可观擦性（Observability）。 我们再来大致看一下 CNCF 的全景图： 图片 - landscape.png 我们着重看右上角的 Obervability And Analysis 模块： 图片 - obervability_and_analysis CNCF 赋予了可观察性极高的地位，可观察性和由操作系统、底层网络提供商构成的平台一样，贯穿整个云原生体系。 变化是微服务的本质，也是应用系统设计和研发中唯一不变的准则。 因此，无法通过一张静态的架构图来描述微服务架构下的系统部署情况。 微服务集群的组成元素、依赖惯需、流量分布以及外部边界等都会随着事件发生变化。虽然微服务技术降低了应对变化的难度， 但运维团队却依然需要明确地了解系统的运行情况，这就是微服务系统对可观察性的诉求。 可观察性提供了穿越微服务边界的能力，它先对应用数据或管理平台数据进行观测及后台分析，然后通过高度可视化系统，直观地将系统当前的状态展现出来。 层次划分 根据观察层次的不同，谈论可观察性时一般涉及基础设施层、工具层和应用环境层。 基础设施层：对云主机、操作系统、云服务进行包括可用性在内的基础指标监控，提供云服务商的基础运维支持能力。 工具层：编排工具的可观察性是微服务体系中的重要一环，随着容器化的不断推进，对 Kubernetes 和 Mesos 等容器编排生态工具的监控也越来越多样化。另外，由于 DevOps 体系的发展，相关工具链（如Git、SVN、CI/CD等）的可观察性也成为当今的关注焦点。 应用环境层：应用环境层的可观察性是指对应用服务器、数据库、消息队列、缓存等中间件组件进行观察。 由于基础设施层的监控和系统健康度观察大多由平台提供商直接负责，而工具层的解决方案基本是由其核心产品以及周边生态提供的，因此对于微服务和云原生应用开发者来说，关注点应集中在应用环境层。 应用环境层因为涉及业务系统，所以场景变化也是最多的。后面就将具体介绍如何进行应用环境层的系统观察。 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"concepts/trace_metrics_loggin.html":{"url":"concepts/trace_metrics_loggin.html","title":"核心概念","keywords":"","body":"核心概念 日志（Logging）、指标（Metrics）和追踪（Tracing）是紧密相关的三个核心概念。下面这张图能够很清楚的描述了这三者之间的关系： 图片 - tracing_Logging_metrics.jpg 日志（Logging） 日志描述的是一些不连续的离散时间。例如，有些业务系统采用ELK（Elasticsearch+Logstash+Kibana）或类似技术栈的日志手机系统， 它们是分布式监控系统的早期形态，借鉴了传统应用解决问题的方式，是最容易理解的解决方案。 指标（Metrics） 指标是可累加的，它具有原子性。每个指标都是一个逻辑计量单元，体现了一段时间之内相关指标的状态。 例如：队列当前的深度可以被定义为一个计量单元，在写入或读取时更新；输入 HTTP 请求的数量可以被定义为一个计数器，用于进行简单累加；请求的执行时间可以被定义为一个柱状图，在指定时间片上更新和汇总。 追踪（Tracing） 追踪在监控领域通常被称为分布式追踪，是指在单次请求范围内处理信息。任何的数据和元数据信息都被绑定到了系统中的单个事务上。 追踪能力是近几年技术人员最为关注的需求，由 Twitter 开源的 Zipkin 是目前运用最为广泛的分布式追踪系统之一。 上面介绍的三个概念并不是相互独立的，往往会有一定的重叠，复杂和完善的监控系统一般是跨越多个维度的。 追踪（Tracing）+ 日志（Logging）：这是多数分布式追踪系统的早期形态，通过简单的上下文传递，可以将请求的上下文ID输出到日志，让日志具备时间维度之外的另外一个关键维度——上下文关联。通过时间和上下文关联让这两个维度的组合，用户可以快速感受到分布式追踪带来的强大优势。 日志（Logging）+ 指标（Metrics）：这是日志分析系统的常规架构，可通过系统现有的业务日志获取相关的指标数据。 追踪（Tracing）+ 指标（Metrics）： 用于指明基本分布式追踪系统的数据分析指标、应用间的关系以及数据流向等。 日志、指标、追踪可以看作功能全集中的元素，一些商业级别的 APM （Application Performance Managment，应用性能管理） 系统便采用 “追踪+指标”的方式提供一体化的解决方案。 充分理解这三个概念，能够更好定位目前市面上的各种开源和商业监控体系工具，理解它们的核心优势。 后面就将介绍分布式追踪系统。 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"tracing_system/":{"url":"tracing_system/","title":"分布式追踪","keywords":"","body":"分布式追踪 概述 分布式追踪的概念源自最早面对超大规模分布式场景的 Google 公司于2010年发表的论文——《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》。 论文中详细地介绍了 Google 的 Dapper 系统实现及原理，Dapper 的核心算法是在分布式请求的上下文中加入 span id 以及 parent id , 用于记录请求的上下级关系，如下图所示： 图片 - dapper-01.png 阿里巴巴公司曾经分享过鹰眼系统的实现方案，也是国内早期的分布式追踪系统实现方案，鹰眼系统使用类似书签索引，简化了 parent id 和 span id 的表达方式, 一个浏览器请求可能触发的系统间调用如下图所示： 图片 - ali-edge.png 鹰眼系统与 Dapper 在原理上没有本质区别。之所以在这里提及，是因为鹰眼系统的编码方案可以帮助读者理解 Trace 树形结构。但是，需要强调的是，Trace 并非只有树形结构，对于消息消费、异步处理等批量模型，会出现一条 Trace 关联多个 TraceId 的情况。 目前常见的开源解决方案 Apache Zipkin 是起步最早、社区生态最为完备的分布式追踪系统解决方案。它借助了稳定的 API 库以及广泛的集成，几乎覆盖了从开源到商业级别的分布式系统的各个角落。 其覆盖的语言包括 Java、C#、Go、JavaScript、Ruby、Scala、C++、PHP、Elixir、Lua等，甚至为每种语言都提供了不止一种 API 库，更好地适应了各种不同的应用场景。 OpenTracing 是 CNCF 托管的分布式追踪项目，它的官方定位是针对分布式追踪的 API 标准库，与厂商无关，旨在为不同的分布式追踪系统提供统一的对外 API 接入层。 因此，OpenTracing 并不包含任何实现，可以将它理解为接口协议，类似于 Java 的数据库访问接口 JDBC。 需要强调的是，OpenTracing 只是一套可选的接口 API 库，并非分布式追踪的实现标准，其原生支持者同样是 CNCF 托管的项目——Jaeger。另外，前面提到的运用最为广泛的分布式追踪系统 Zipkin 并不是 OpenTracing 的主要支持，Zipkin 具有完全独立的规范、协议和 API 接口。所以到目前为止，还不能承认 OpenTracing 是分布式追踪领域的 API 标准。 OpenCensus 来自于 Google，是2017年才崭露头角的新兴项目。它的定位介于 OpenTracing 和 Zipkin 之间，提供了统一的 API 层，同时提供了部分实现逻辑。 工程师只需在 OpenTracing 的基础上自定义实现最小范围的逻辑（比如上下文传递和数据格式上行）即可。 OpenCensus 目前支持发送 Zipin、Jaeger、 Stackdriver 和 SignalFx 格式的数据。 OpenCensus 在 Google 的大力支持下，已经成为 OpenTracing 的有力竞争者。 OpenTracing vs OpenCensus 两套Tracing框架，都有很多追随者，都想统一对方，如下图对比了 OpenTracing 和 OpenCensus: 图片 - opentracing_opencensus 可以看到，OpenTracing和OpenCensus从功能和特性上来看，各有优缺点，半斤八两。OpenTracing支持的语言更多、相对对其他系统的耦合性要更低；OpenCensus支持Metrics、从API到基础框架都实现了个遍。既然从功能和特性上分不出高下，从知名度和用户数上来看做对比： 图片 - opentracing_opencensus_users 可以看到基本平衡，OpenTracing有很多厂商追随（比如ElasticSearch、Uber、DataDog、还有国产的SkyWalking），OpenCensus背后Google和微软两个就够撑起半边天了。 OpenTelemetry 横空出世 所谓天下合久必分、分久必合，既然没办法分个高低，谁都有优劣势，咱们就别干了，统一吧。于是OpenTelemetry横空出世。 那么问题来了：统一可以，起一个新的项目从头搞吗？那之前追随我的弟兄们怎么办？不能丢了我的兄弟们啊。 放心，这种事情肯定不会发生的。要知道 OpenTelemetry 的发起者都是 OpenTracing 和 OpenSensus 的人，所以项目的第一宗旨就是：兼容 OpenTracing 和 OpenSensus。对于使用 OpenTracing 或 OpenSensus 的应用不需要重新改动就可以接入 OpenTelemetry。 核心工作 OpenTelemetry 可谓是一出生就带着无比炫目的光环：OpenTracing支持、OpenSensus支持、直接进入CNCF sanbox项目。但OpenTelemetry也不是为了解决可观察性上的所有问题，他的核心工作主要集中在3个部分： 规范的制定，包括概念、协议、API，除了自身的协议外，还需要把这些规范和W3C、GRPC这些协议达成一致； 相关SDK、Tool的实现和集成，包括各类语言的SDK、代码自动注入、其他三方库（Log4j、LogBack等）的集成； 采集系统的实现，目前还是采用OpenSensus的采集架构，包括Agent和Collector。 可以看到OpenTelemetry只是做了数据规范、SDK、采集的事情，对于Backend、Visual、Alert等并不涉及，官方目前推荐的是用Prometheus去做Metrics的Backend、用Jaeger去做Tracing的Backend。 图片 - opentelementry 看了上面的图大家可能会有疑问：Metrics、Tracing都有了，那Logging为什么也不加到里面呢？ 其实Logging之所以没有进去，主要有两个原因： 工作组目前主要的工作是在把OpenTracing和OpenSensus的概念尽早统一并开发相应的SDK，Logging是P2的优先级。 他们还没有想好Logging该怎么集成到规范中，因为这里还需要和CNCF里面的Fluentd一起去做，大家都还没有想好。 终极目标 OpenTelemetry的终态就是实现Metrics、Tracing、Logging的融合，作为CNCF可观察性的终极解决方案。 Tracing：提供了一个请求从接收到处理完毕整个生命周期的跟踪路径，通常请求都是在分布式的系统中处理，所以也叫做分布式链路追踪。 Metrics：提供量化的系统内/外部各个维度的指标，一般包括Counter、Gauge、Histogram等。 Logging：提供系统/进程最精细化的信息，例如某个关键变量、事件、访问记录等。 这三者在可观察性上缺一不可：基于Metrics的告警发现异常，通过Tracing定位问题（可疑）模块，根据模块具体的日志详情定位到错误根源，最后再基于这次问题调查经验调整Metrics（增加或者调整报警阈值等）以便下次可以更早发现/预防此类问题。 Metrics、Tracing、Logging融合的关键 实现Metrics、Tracing、Logging融合的关键是能够拿到这三者之间的关联关系.其中我们可以根据最基础的信息来聚焦，例如：时间、Hostname(IP)、APPName。这些最基础的信息只能定位到一个具体的时间和模块，但很难继续Digin，于是我们就把TraceID把打印到Log中，这样可以做到Tracing和Logging的关联。但这还是解决不了很多问题： 如何把Metrics和其他两者关联起来 如何提供更多维度的关联，例如请求的方法名、URL、用户类型、设备类型、地理位置等 关联关系如何一致，且能够在分布式系统下传播 在OpenTelemetry中试图使用Context为Metrics、Logging、Tracing提供统一的上下文，三者均可以访问到这些信息，由OpenTelemetry本身负责提供Context的存储和传播： Context数据在Task/Request的执行周期中都可以被访问到 提供统一的存储层，用于保存Context信息，并保证在各种语言和处理模型下都可以工作（例如单线程模型、线程池模型、CallBack模型、Go Routine模型等） 多种维度的关联基于Tag（或者叫meta）信息实现，Tag内容由业务确定，例如：通过TrafficType来区别是生产流量还是压测流量、通过DeviceType来分析各个设备类型的数据... 提供分布式的Context传播方式，例如通过W3C的traceparent/tracestate头、GRPC协议等 下面是Yuri Shkuro画的原型设计： 图片 - opentelementry_yuri 当前状态以及后续路线 目前OpenTelemetry还处于策划和原型阶段，很多细节的点还在讨论当中，目前官方给的时间节奏是： 2019年9月，发布主要语言版本的SDK（Pre Release版） 2019年11月，OpenTracing和OpenSensus正式sunsetted（ReadOnly） 未来两年内，保证可以兼容OpenTracing和OpenSensus的SDK 从Prometheus、OpenTracing、Fluentd到OpenTelemetry、Thanos这些项目的陆续进入就可以看出CNCF对于Cloud Native下可观察性的重视，而OpenTelemetry的出现标志着Metrics、Tracing、Logging有望全部统一。 但OpenTelemetry并不是为了解决客观性上的所有问题，后续还有很多工作需要进行，例如： 提供统一的后端存储，目前三类数据都是存储在不同系统中 提供计算、分析的方法和最佳实践，例如动态拓扑分析 统一的可视化方案 AIOps相关能力，例如Anomaly Detection、Root Cause Analysis等 参考 OpenTelemetry-可观察性的新时代 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"tracing_system/apm_observability.html":{"url":"tracing_system/apm_observability.html","title":"应用性能管理与可观测性平台","keywords":"","body":"应用性能管理与可观测性平台 APM(Application Performance Monitoring, 应用性能管理)经常和分布式追踪同时出现，但两者却有着明显的差异。 APM 由来已久，已经有十几年的历史，自最早的以 Weblogical 为代表的 J2EE 应用出现开始，APM 就逐渐受到了各大厂商的重视， 并作为商业软件的组成部分被提供出来。 APM 系统为单体式应用和分布式应用提供了全面的可视化展现建议、性能分析建议、性能诊断和优化建议，为开发团队、运维团队提供了常规监控体系之外的保障。 随着分布式应用监控难度的增加，应用性能问题的发现和定位变得越来越困难。在分布式系统中，传统的以日志为主的监控系统正在越来越多地被用来 进行基础设施、网络环境的监控。而应用层面上，日志监控基本失去了定位问题的能力，尤其是在上云之后，网盘逐渐成为主流，日志的有效性问题、写入压力和成本问题凸显出来。 因此，人们对 APM 系统提出了越来越高的要求，分布式追踪、非侵入式的语言探针、轻量化、低延迟分析，这些都是对新时代 APM 提出的基本要求，也是对传统 APM 系统的挑战。 分布式追踪 前面对分布式追踪做了详细的介绍，分布式追踪能完成日志监控的绝大部分功能，提供更好的使用内存而非文件系统，解决性能定位问题。 Google、Twitter、Uber、Pivotal等各个大公司在这个领域投入了极大的精力。 非侵入式的语言探针 这一点恰恰和“分布式追踪”的需求矛盾，因为无论是自动探针（Agent）还是手动探针（SDK），本质上都是对监控的目标程序进行了修改，且任何修改都是有一定风险的。而在语言众多，团队小型化、多元化的云原生时代，语言探针在能力上虽然十分吸引人，但使用成本却很高，所以非侵入式的语言探针，即非语言探针，被人们提了出来，可以在用户不需要分布式追踪和方法级诊断的情况下完全做到和语言无关。 轻量化 传统的 APM 系统使用大量的大数据技术栈，如使用Spark、Storm、Hbase等，虽然功能完善，但是运维难度很大。监控系统可能比被监控系统更难运维，这显然不是一个好的设计。大量的中小型公司需要的正是非大数据的 APM 解决方案。只有以 Elasticsearch 或 Mysql 为核心，使用非大数据框架结局方案，才能更好地在新兴的云原生环境下提供服务。 低延迟分析 系统的分布式压力变化很快，APM 系统能够做出秒级反应，而不是像使用报表系统一样需要 3 分钟以上才能对数据做出反应。这里需要注意，很多公司把流量分析、经营分析的系统指责加到 APM 系统，这样会造成低延迟和轻量化性能的降低。实际上，APM 可以作为流量分析、经营分析的系统数据源，但是应该专注在可观察性、指标分析以及告警上。 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"tracing_system/PS_deep_into_obserbility.html":{"url":"tracing_system/PS_deep_into_obserbility.html","title":"附:《万字破解云原生可观测性》","keywords":"","body":"现在是一个云原生时代，任何一个玩技术的都或多或少跟云计算、容器、Kubernetes、云原生应用有着不同的渊源密切。 这就导致了现在公司对应用的技术的选型以及对应用的监控、管理发生了很大的变化。 特别是对20年以前，或者说20年以来应用系统的变迁也是非常明显的，这中间有很多个分水岭。 图片 - 软件架构 最初我们开始学习开发的时候可能都是从主机模式着手，随后学习基于 C/S 架构的开发模式，接着是从 J2EE 的流行到现在的微服务和基于容器的服务，以及目前比较热门的基于流程编排的开发架构。但我们发现，虽然开发、迭代、交付的效率得到了很大的提升，但是系统或者应用变得稍微复杂了一些。 那么在今天这样一个云原生时代呢，我们应该以什么样的方式对云原生应用进行监控和管理呢？ 这就可能要涉及到另外一个话题，也就是本篇文章着重讲解的话题——《可观测性》。我将试图在本文中，帮助大家梳理清楚什么是可观测性。如果你觉得这一点很重要或者认可对云原生应用进行监控、管理的理念，那么我将阐述我对如何针对你的应用去建设这样一个可观测性的系统或者平台的一些实践经验。 首先需要说明的是：可观察性是一套理念系统，没有对技术的具体要求。其重点是团队要融入可观察性的理念，特别是要求研发写出的应用是可观察的。将可观察性包含在你的需求之中，它是与扩展性，可用性同等重要的非业务性需求。 Apple 的工程师 Cindy Sridharan 的博文“监控与观察”（Monitoring and Oberservability）首次将 Oberservability 一次带入开发者的视野。 然而，在谷歌，Google 著名的 SRE 体系在以上 Cindy Sridharan 提出可观测性之前就已经奠定了可观察性的理论基础，也就是说在微服务、可观测性等概念或者出现以前，前辈们将这套理论称为监控，其中 Google SRE 特别强调白盒监控的重要性，而将当时技术圈常用的黑盒监控放在了相对次要的位置。而白盒监控正是应和了可观察性中“主动”的概念。 这里我引用一下 Baron SchSchwarz 大咖的一个定义：“监控告诉我们系统的哪些部分是工作的。可观测性告诉我们那里为什么不工作了。” 上面这句话即定义了可观测性，也告诉了我们可观测性和传统的监控的区别。从引用来看，可观测性似乎更有助于我们诊断系统健康与否。如果我们发现监控系统告诉我们被监控对象的监控状态全都是“绿色”，一切万事大吉，一切都天下太平的话，那么可能监控本身也没有什么价值，存在的意义也不大。 到这里，监控和可观测性之间细微的区别就已经很清楚了。 正因为 SRE 在整个云原生运动中的突出地位，越来越多的团队意识到，应该从系统建设之初去主动的规划监控指标。特别在一些强调自己云原生特性的项目，如 Linkerd，traefik 等，会主动设计可观测系统内部状况的入口。这些入口包括但不限于，Promethues 的 endpoint、Zipkin 协议的支持等。 可观测性的立场是站在被观测对象（也就是你目前运行的云原生应用）之上，他的出发点是被监控的对象。 本文也将再次回顾一下如何基于被观测对象的角度来审视如何构建一个可观测性平台。我将采取四步法的方式来循序渐进的构建你目前已存在的或者未来想要构建成的可观测性。我们更加着重关注的是在每一步中可能存在的难点与挑战。 那么今天通过本文，我期望你能够有一个全面的认识和更加全面的感知。尤其是对你应用系统新的监控思维、理念。 一般对公司运维团队来说，我们比较痛苦的是当监控系统显示状态为“绿色”的情况下，我们的客服系统却被打爆了。业务部门的同事也来向你投诉，业务系统已经不能正常工作了。这是比较尴尬的窘境。 另外一种情况就是你自己也已经发现监控系统已经爆红了，不是红就是黄色警告状态。当你看到这样一个悲观的场面时，监控系统也没办法告诉你到底是哪里不工作了，以及为何不工作了。 为了解决这样的窘境呢，我们希望能有一种新的思维，站在应用系统本身出发去探讨另外一个概念或者特性——应用系统的可观测性。尤其是最前面提到的在当今云原生时代下的应用系统的可观测性。 我们来回顾一下提供可观测性的大背景，正如前面提到的云原生应用，云原生应用目前是大行其道，它不仅是一个简单的名次，其内容也是丰富多彩。其内容主要涉及到以下三大点，可以牵强/不负责任的认为，没有和以下三点强相关的话就不叫做“云原生应用”： 首先是应用架构发生了变化： 从单体应用向微服务过渡 应用架构过渡为松耦合系统 应用版本迭代更快、周期更短 基础设施层发生了变化： 容器化、应用自身快、轻、微 Kubernetes 成为运行容器的默认平台 Iaas、Paas 和 Caas 平台底层来承载 Kubernetes 平台 软件生命周期： 服务通过 DevOps 流水线持续部署 服务变更低成本和低风险 呈现高频率和全自动变更 我们来详细的看一下，下图算不算是一个云原生应用： 该互联网应用实现了多区部署、负载均衡、多应用副本、自动扩容、数据库读写分离副本。 其实判断一个应用符不符合云原生还得看他是否符合 12要素（12-Factor），这12要素 其实蛮重要的，特别是在微服务年代又被再次热议。上面这张图本身是一个传统架构通过虚拟机部署的应用。他也使用到了云计算或者说云计算当中很多关键的服务，比如基于地域的DNS、基于Cloud 提供的负载均衡，数据库也是使用 RDBS 在区域内实现高可用、读写分离等机制。这样来看的话这也可以认为是符合了12因素的云原生应用。只不过它不是一个容器化的云原生应用，但它也在 Cloud 运行。当然，容器化之后的云原生应用或许更加优雅、美丽动人。 不过话又说回来，一旦你践行了服务拆分进行微服务之后，或许面临着如下这种场景： 规模化的微服务对我们分布式系统的要求提升： 需要在分布式系统下确保我们的服务发现/注册中心的可用性； 必须面对容器化环境给我们系统带来的挑战； 多个服务之间的依赖关系变得复杂无比，需要通过一定 DevOps 手段来对系统进行治理。 同时也对我们如何对其监控带来了挑战： 微服务的规模和动态性使得数据收集的成本大幅度提高，例如 CPU 、内存和网络传输的开销。 大量的监控数据对后台数据处理分析的产生影响，服务体量非常大的情况下，出现了问题之后，如何快速定位到发生问题的根本原因上。 对于可视化和关联分析的要求方面，传统APM缺少好的手段。 另外从应用的生命周期来看，应用在生成环境的部署只是一个开始。 对于开发人员来讲，应用上线并不能够万事大吉、高高挂起。这也许是后面痛苦的开始，即使你的系统架构设计得再好，也没有人能够完全的保证自己的系统不会出现宕机的情况。我们不光要运维好系统，还得做好时时刻刻恢复系统的准备。 然而在如今云原生时代，或者说在分布式系统时代，系统故障点可能出现在任何地方，任何地方都有出现故障的隐患。这也许会让你开始觉得分布式系统或许开始变得不那么美好。 那么我们有没有更好的方式来及时发现这些隐患呢？ 我们要重新开始思考以前的监控的做法以及尝试新的手段。上面这张图的左边想突出的是传统的监控妄图通过显微镜一样，无限放大、放大查看很细节。 然而，在规模化微服务之后，你可能连宏观的关联关系都还没有发现，更别说是放大地去查看。 由于如今采用容器化之后，可能基础设施都已经不受我们太强的控制。所以，现在更多的是希望在这样一个云原生系统下的遥测。 前面花了大量篇幅来说明监控到可观测性的演变，以及两者的区别。一图胜千言： 正如上面卫星遥测一样，我们希望通过寻找系统的一些比较饱满的信号量，便于我们对系统的了解。 传统的运维可能只能给我们带来最顶层的“告警”和“概况”。那么当应用系统宕机或者一些别的原因，运维需要更深层次的错误信息排错的时候，可能会将研发人员纳入该过程去剖析。比如应用运行时的 profile（Profiling 技术是一种在应用运行时收集程序相关信息的动态分析手段，常用的JVM Profiler可以从多个方面对程序进行动态分析，如CPU、Memory、Thread、Classes、GC等），甚至是需要研发人员去分析服务于服务之间的关联关系。 从上图来看，可观测性包含了传统监控的范畴。总的来看这一套“信号量”显得有点复杂，我们尝试将其精简一下： 我们把它精简成为三根支柱，也可以认为“可观测性是由日志、指标和追踪三根支柱去构建的”。 一般社区在交流的时候也会选用如下这张图去讲解： Lgging，展现的是应用运行而产生的事件或者程序在执行的过程中间产生的一些日志，可以详细解释系统的运行状态，但是存储和查询需要消耗大量的资源。所以往往使用过滤器减少数据量。 Metrics，是一种聚合数值，存储空间很小，可以观察系统的状态和趋势，但对于问题定位缺乏细节展示。这个时候使用等高线指标等多维数据结构来增强对于细节的表现力。例如统计一个服务的 TBS 的正确率、成功率、流量等，这是常见的针对单个指标或者某一个数据库的。 Tracing，面向的是请求，可以轻松分析出请求中异常点，但与 logging 有相同的问题就是资源消耗较大。通常也需要通过采样的方式减少数据量。比如一次请求的范围，也就是从浏览器或者手机端发起的任何一次调用，一个流程化的东西，我们需要轨迹去追踪。 上面通过大篇幅的对云原生时代大背景以及可观测性的结构之后，且在你认可上面观念的情况下，应该如何针对我们目前存在的系统或者正在开发运维的系统进行可观测性的建设呢？ 为了大家更好的理解，我这里采用了直白的四步法，供你们参考，同时你也可以结合你们目前本身的情况进行对比： 图片 - 可观测性建设四步法 0 健康检查 健康检查属于第一步，在这一步，我们需要通过一些手段能够知道我们的系统是否处于运行状态、是否能够正常处理工作以及是否能够处理更多的工作？抽象地认为是一个服务运行状态的红绿灯系统，通过红绿灯信号量，能够显而易见的知道当前应用运行状态。 总的来讲，有三种方式来实现这样的“红绿灯系统”： 1、通过广播的方式，将自身健康状态信息发送到指定地方，以此来更新自己以及邻居节点的状态。 2、 通过注册表的方式，将自己的服务 IP、Port 写入到比如 Eureka、Etcd、Zookeeper 等服务清单中。 3、 通过接口暴露自己的健康状态，比如在应用中实现类似 /health 指定的接口，并返回统一的格式。这种方式可能是更为普遍的一种实现方式。一般可以通过集成 Prometheus 或者在 Java Spring Boot 中 通过 Actuator 实现。之后需要采用工具或者自己实现相关服务来轮训查询健康状态。 例如：在 Java 服务中通过 Actuator 暴露 /health 接口的返回信息： { \"description\":\"User Service Server\", \"healthy\":\"true\", \"denpendencies\":[ { \"name\":\"mysql\", \"healthy\":\"true\" } ] } 你也许会认为应用健康检查属于运维人员去关心的，但其实作为应用开发人员就应该去考虑为你的应用添加此特性或者此功能，该特性与你的应用处理的业务流程的重要性应该被同等对待。 上面只是提供了三种让你可以参考的方式，但是该步骤完成之前，你可能需要去考虑如何定义健康——即何谓健康？以及需要注意健康检查的程度，避免过度检查造成 DDOS 给应用带来影响。 1 指标 紧接着第二步则是指标监控，首先来回顾一下何谓指标？ 指标是在许多个连续的时间周期里度量的 KPI 数值。 比如我们常常谈到的一个应用在过去十分钟、半小时内的CPU、内存占用率以及平均占用率等等。 同时呢，一般情况下会将指标进行分类： 系统指标：CPU 使用率、磁盘使用率以及网络宽带情况等等。 应用指标：出错率、SLA（服务等级协议）、APDEX（服务满意度）、平均延时等等。 业务指标：用户会话、订单数量和营业额等等。 对于上面系统、应用这两种指标来讲，一般能够通过一些开箱即用的工具来实现。比如 Zabbix、Prometheus、Elastic MetrciBeat等等。 需要强调的是业务指标，像前面提到的健康检查一样，需要开发者考虑并将其与业务处理流程同等对待。 这里列举了一个最常用的指标采集模式: 左边的监控对象包括了很多基础设施，比如服务器、应用框架、中间件和业务服务。其中每个监控对象都有不同的采集方式，如果说在如今云原生环境下的话，可能 Prometheus 这种自暴露的方式被广泛地使用。 但是，也不要对指标过度地依赖，比如我们在做告警分析的时候，要注意并不是每个指标都值得告警，真正需要告警的是针对影响用户端征兆的告警；实时查询意味着鉴于存储成本，数据无法长期保留；传统的静态阈值管理需要根据业务高峰期动态地调整，以此达到可能性预测；数据的聚合、统计、分析和展示需要耗费一定的开发人力成本以及计算需要消耗大量时间和存储成本。 2 日志 恭喜你，成功进阶到日志阶段。日志记录了每件事情，并能够提供发生过什么事情的“证据”。这里拿 Nginx 日志来看： 192.168.1.22 - - [1/May/2020:10:41:46 +0000] 56422 \"GET / HTTP/1.1\" 200 396 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36\" 其中记录了远端 IP，发生请求的时间以及相应状态和数据大小。 当然，这是你的系统中一种日志，你还有系统中不同服务的后端用于排错的 Debug、错误日志等等。 因此，得有一定的手段来集中管理大量日志数据，这里提一下三个前提条件： 可集中化：传统的可能是运维通过 SSH 连到机器上手动过滤、搜索关键日志。想象一下，当你们系统出现问题之后，你的老板站在你身后看着你打开了四五个，甚至更多的窗口滚动着不同的日志。 可全文检索：在上面日志集中化之后，我们需要根据不同维度、关键词进行检索，从大量日志中检索自己期待的日志数据。 可关联：这一步可能是在检索之后提高排错或者说日志检索更为重要的一步，在多个索引之间可以通过时间节点、业务系统调用逻辑等角度进行横向关联分析与比对。 这里额外地针对细化日志关联做一点补充，特别是在如今微服务系统盛行的今天，通过事件将日志进行关联分析形成信息流是尤为重要的，以 Dapper 论文中的调用图为例： 这个路径由用户的X请求发起，穿过由一系列服务组成的系统。 想象一下，当用户的请求出现问题之后，你会从哪里开始排查问题呢？ Dapper 论文中提到的解决方法是：当请求发起时，创建全局的ID，并将其随着后续请求的调用传递下去，同时被调用的服务需要将该 ID 和你的事件绑定在一起。 简单来讲，目前普遍的方法就是在日志中集成 TraceId 形成日志信息流。在上面集中化的日志系统中进行查询时，能够通过该 TraceId 进行查询，将A、B、C、D、E不同服务对该次请求的处理流搜索出来。 3 应用链路追踪 试想一下，服务的健康检查全都是绿色，指标也是绿色的，日志系统中也没有报错。但是总会有一些用户抱怨，某个操作响应很慢或者点击出现 500 错误等等。 公司业务部门找到了运维团队，客服电话也被轰炸。如何破解此囧境？ 目前较多的手段则是通过链路追踪的方式来辅助运维团队。市面上也有很多 APM 厂商，国内外也有很多开源的链路追踪系统，比如国外的 Jaeger、Pinpoint、Zipkin、Elastic APM，国内的 Skywalking。由于我也参与 Apache Skywalking 项目管理以及相关贡献，那我此处就以 Skywalking 举例： 我从 Skywalking 抓取了一张截图，Skywalking 通过探针将一次请求将链路串联起来，以此实现在用户抱怨之前提前洞察出一些问题。 另外，我也抓取了 Elastic APM 的架构图以供参考： 到这里可观测性的四步法也基本上讲述完了，假设你一步一步地进行建设走过来，那么我也相信你也初步构建好了你的可观测性。但是，任何系统都不一定能满足你的所有需求，只能多做一些准备，准备得越充分，才能走得更远更牢固。 现在再来回顾一下构建可观测性，他并不是非黑即白的东西，更像是一个光谱， 越靠左的作用是帮助我们了解、监控系统的可靠性，越靠右则是帮助我们进行排错与一些探索。 最后来总结一下实施可观测性的关键： 成本低的追踪埋点：针对运维团队或者公司层面来讲，降低实施可观测性的成本。 浏览和查询友好：支持日志、指标和链路之间的关联，支持复杂运维场景的定制。 可靠性：能够应对高速大数据量写入与查询，能够应对数据线性规模的增长以及集中式访问。 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"tracing_system/skywalking/skywalking_intro.html":{"url":"tracing_system/skywalking/skywalking_intro.html","title":"介绍","keywords":"","body":"Apache Skywalking 介绍 Apache Skywalking(http://skywalking.apache.org) 定位于一款专为微服务、云原生架构和基于容器（Docker、K8s、Nesos）架构而设计的分布式系统应用程序性能监控工具。 SkyWalking 是观察性分析平台和应用性能管理系统。提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。 Skywalking 从以大数据平台为主的分析模式，进化为轻量化、低延迟的分析模式，同时支持分布式追踪和非侵入式的语言探针这两种模式，是能够提供一致性解决方案的开源项目。 自项目 创建至今，大家会发现，Skywalking 在不停地进行大规模的重构、迭代和演进，强大的开源社区力量是项目能够得到良好发展的根基。 目前项目有两条主线分支： 5.x 版本分支：稳定版本，处于维护状态，主要用于修复版本Bug以及扩展语言探针插件。 6.x 版本分支：目前也处于稳定版本，目的是替代 5.x 版本成为主推的生产分支，提供了基于语言探针和 Service Mesh 探针的数据收集，具有统一可定制化的数据分析、数据展现能力。 8.x 版本分支：目前最新分支。基于 6.x 与 7.x 版本，去掉了探针注册、OAP 缓存逻辑，完全不兼容以前的版本。支持 Prometheus 指标并提供了 UI 可修改功能。同时增加了 Python 探针。在 Service Mesh 场景有更多的提升。 Skywalking 可观察性分析平台 Skywalking 不局限于以往的基于多语言探针的思想，它面向多数据源，可提供统一、高效、可定制化的可观察性分析平台解决方案，如下图所示： 图片 - Skywalking 可观察性分析平台 可观察性分析平台（Observability Analysis Platform, OAP） 是 Skywalking 社区 PMC 团队提出的新概念，OAP 将可观察性分为两个维度和三个层面： 两个维度 Tracing 追踪链路数据 Metrics 指标数据 三个层次 Receiver 接收器，针对不同协议提供解析和适配能力。Skywalking 除了接收原生的 Trace、Metrics 数据，同时兼容了 Zipkin、Jaeger 的 Trace 数据。8.x 支持了 Prometheus 指标的接收。 Analysis Core 分析内核，提供面向 Source 分析源的流式分析方法，并派生出 OAL(Observability Analysis Language，可观察性分析语言) 来描述流式分析。支持文件配置级别的指标自定义。 Query Core 查询内核，基于拓扑结构、基础数据和指标数据等多个维度提供基于 GraphQL 的查询，为页面和第三方系统集成提供支持。 Skywalking 生态 除了以上提到的内容之外，Skywalking 活跃的社区为 Skywalking 提供了丰富的生态产品，其中包括辅助运维部署与监控的 GUI/CLI 、Skywalking Kubernetes 部署方案等等。 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"tracing_system/skywalking/feature.html":{"url":"tracing_system/skywalking/feature.html","title":"功能介绍","keywords":"","body":"Skywalking 功能介绍 本篇首先从 UI 使用层面上来介绍 Skywalkalking 的核心功能特性。 可配置的仪表盘 图片 - skywalking-dashboard-01 图片 - skywalking-dashboard 仪表盘提供了针对全局（Global）、服务（Service）、端点（Endpoint）、实例（Instance）四个不同粒度的观测角度，方便我们从全局到具体的进行观测系统的健康并及时发现那些糟糕的信号量。 由于 Skywalking 提供了较多的指标数据，其中新版本中更是包括了从 Prometheus 接收的指标数据以及自身监控指标。这就导致之前的 UI 展示的指标信息可能并不是每个人都关心或者对用户更加直观的数据。 因此，在 8.0 版本中，新增了对仪表盘指标报表自定义展示，并支持保存自定义仪表盘为模版的个性化需求。 图片 - skywalking-dashboard-template 新的拓扑关系 新的拓扑图中，除了支持我们为一组服务创建一个分组来帮我们梳理服务与服务、应用与应用的关系之外，还新增了直接从拓扑节点进行关联指标数据查询。省去了不同页面之间来回跳转的尴尬局面。 Trace 展示多样化 链路展示与查询功能上，支持列表、树结构、表格三种不同的展示方式，满足了不同用户查看或者追踪链路的习惯。 性能剖析 Profile 在系统性能监控方法上，新版 Skywalking 提出了代码级性能剖析这种在线诊断方法。这种方法基于一个高级语言编程模型共性，即使再复杂的系统，再复杂的业务逻辑，都是基于线程去进行执行的，而且多数逻辑是在单个线程状态下执行的。 代码级性能剖析就是利用方法栈快照，并对方法执行情况进行分析和汇总。并结合有限的分布式追踪 span 上下文，对代码执行速度进行估算。 http://skywalking.apache.org/zh/blog/2020-03-23-using-profiling-to-fix-the-blind-spot-of-distributed-tracing.html 指标对比 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"installation/":{"url":"installation/","title":"安装部署","keywords":"","body":"安装与部署 此部分将讲解如何通过下载的压缩包、容器以及 Kubernetes 部署 Skywalking。 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"installation/script_way/":{"url":"installation/script_way/","title":"shell 脚本部署","keywords":"","body":"Shell 脚本部署 首先需要从官方下载压缩包并解压，不同版本下载地址：http://skywalking.apache.org/downloads/ 或者 http://skywalking.apache.org/downloads/ 此处以 8.1.0 为例: Skywalking 发行包里面包含了 apache-skywalking-apm-8.1.0.tar.gz 和 apache-skywalking-apm-es7-8.1.0.tar.gz，两者唯一不同之处是所使用的 Elasticsearch 版本不同。前者适用 Elasticsearch 6.x 版本作为存储，后者带有 es7 标识的则代表适用 Elasticsearch 7.x 版本作为存储。 以 Elasticsearch 6.x 即 apache-skywalking-apm-8.1.0.tar.gz 为例： ⾸先点击右边地址下载 Skywalking 安装包: https://www-us.apache.org/dist/skywalking/8.1.0/apache-skywalking-apm-8.1.0.tar.gz; 或者在Linux系统中执⾏行行如下命令: 下载压缩包 $ wget https://www-us.apache.org/dist/skywalking/8.1.0/apache-skywalking-apm-8.1.0.tar.gz 解压缩之后 $ tar -zxvf apache-skywalking-apm-8.1.0.tar.gz $ ls apache-skywalking-apm-bin LICENSE README.txt bin licenses webapp NOTICE agent config oap-libs 配置文件预览 在正式部署之前，建议你大致浏览一下 config 目录下的 application.yml 文件。该文件涉及 Skywalking 部署模式的选择， 部署模式可以通过 cluster.selector 参数进行设置，一版建议通过环境变量 SW_CLUSTER 设置，如下则代表默认使用 standalone 单机模式部署： ······ cluster: selector: ${SW_CLUSTER:standalone} standalone: # Please check your ZooKeeper is 3.5+, However, it is also compatible with ZooKeeper 3.4.x. Replace the ZooKeeper 3.5+ # library the oap-libs folder with your ZooKeeper 3.4.x library. zookeeper: nameSpace: ${SW_NAMESPACE:\"\"} hostPort: ${SW_CLUSTER_ZK_HOST_PORT:localhost:2181} # Retry Policy baseSleepTimeMs: ${SW_CLUSTER_ZK_SLEEP_TIME:1000} # initial amount of time to wait between retries maxRetries: ${SW_CLUSTER_ZK_MAX_RETRIES:3} # max number of times to retry # Enable ACL enableACL: ${SW_ZK_ENABLE_ACL:false} # disable ACL in default schema: ${SW_ZK_SCHEMA:digest} # only support digest schema expression: ${SW_ZK_EXPRESSION:skywalking:skywalking} kubernetes: watchTimeoutSeconds: ${SW_CLUSTER_K8S_WATCH_TIMEOUT:60} namespace: ${SW_CLUSTER_K8S_NAMESPACE:default} labelSelector: ${SW_CLUSTER_K8S_LABEL:app=collector,release=skywalking} uidEnvName: ${SW_CLUSTER_K8S_UID:SKYWALKING_COLLECTOR_UID} consul: serviceName: ${SW_SERVICE_NAME:\"SkyWalking_OAP_Cluster\"} # Consul cluster nodes, example: 10.0.0.1:8500,10.0.0.2:8500,10.0.0.3:8500 hostPort: ${SW_CLUSTER_CONSUL_HOST_PORT:localhost:8500} aclToken: ${SW_CLUSTER_CONSUL_ACLTOKEN:\"\"} etcd: serviceName: ${SW_SERVICE_NAME:\"SkyWalking_OAP_Cluster\"} # etcd cluster nodes, example: 10.0.0.1:2379,10.0.0.2:2379,10.0.0.3:2379 hostPort: ${SW_CLUSTER_ETCD_HOST_PORT:localhost:2379} ······ 同样的，可以通过 SW_STORAGE 环境变量设置链路追踪、指标数据的存储方式。默认是 H2 存储，不过这只适合在做演示的适合使用。因此你需要选择其他存储，推荐 Elasticsearch 集群。 ······ storage: selector: ${SW_STORAGE:h2} elasticsearch: nameSpace: ${SW_NAMESPACE:\"\"} clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200} protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"} trustStorePath: ${SW_STORAGE_ES_SSL_JKS_PATH:\"\"} trustStorePass: ${SW_STORAGE_ES_SSL_JKS_PASS:\"\"} user: ${SW_ES_USER:\"\"} password: ${SW_ES_PASSWORD:\"\"} secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool. dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index. indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:1} # The index shards number is for store metrics data rather than basic segment record superDatasetIndexShardsFactor: ${SW_STORAGE_ES_SUPER_DATASET_INDEX_SHARDS_FACTOR:5} # Super data set has been defined in the codes, such as trace segments. This factor provides more shards for the super data set, shards number = indexShardsNumber * superDatasetIndexShardsFactor. Also, this factor effects Zipkin and Jaeger traces. indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000} metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000} segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200} profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200} advanced: ${SW_STORAGE_ES_ADVANCED:\"\"} elasticsearch7: nameSpace: ${SW_NAMESPACE:\"\"} clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200} protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"} trustStorePath: ${SW_STORAGE_ES_SSL_JKS_PATH:\"\"} trustStorePass: ${SW_STORAGE_ES_SSL_JKS_PASS:\"\"} dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index. user: ${SW_ES_USER:\"\"} password: ${SW_ES_PASSWORD:\"\"} secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool. indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:1} # The index shards number is for store metrics data rather than basic segment record superDatasetIndexShardsFactor: ${SW_STORAGE_ES_SUPER_DATASET_INDEX_SHARDS_FACTOR:5} # Super data set has been defined in the codes, such as trace segments. This factor provides more shards for the super data set, shards number = indexShardsNumber * superDatasetIndexShardsFactor. Also, this factor effects Zipkin and Jaeger traces. indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000} metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000} segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200} profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200} advanced: ${SW_STORAGE_ES_ADVANCED:\"\"} h2: driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource} url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db} user: ${SW_STORAGE_H2_USER:sa} metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000} mysql: properties: jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"} dataSource.user: ${SW_DATA_SOURCE_USER:root} dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234} dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true} dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250} dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048} dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true} metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000} influxdb: # InfluxDB configuration url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086} user: ${SW_STORAGE_INFLUXDB_USER:root} password: ${SW_STORAGE_INFLUXDB_PASSWORD:} database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking} actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds) fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request ······ 关于其它配置，暂时选择默认的即可，如果你有特别需求，参见后面的配置详解章节。 Skywalking 部署 关于 Skywalking 的所有启动脚本都在 bin 目录下面： oapService.bat oapServiceInit.sh startup.bat webappService.sh oapService.sh oapServiceNoInit.bat startup.sh oapServiceInit.bat oapServiceNoInit.sh webappService.bat 如你所见，你可以选择执行 ./startup.sh 脚本在 Linux/Unix 系统上面部署 Skywalking ，你也可以选择通过 startup.bat 脚本在 Windows 平台上面部署 Skywalking。 除此之外，以 Linux/Unix系统为例，你还可以通过 ./oapService.sh 和 ./webappService.sh 脚本将 Skywalking OAP 后端和 UI 分开部署。不过得注意 UI 与 OAP 后端之间的地址配置正确。 部署完成之后你可以访问 http://localhost:8080 访问 UI。 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"installation/container_way/":{"url":"installation/container_way/","title":"容器化部署","keywords":"","body":"Docker-Compose 容器化部署 前置条件 通过容器部署，你可能需要对 Docker 有所了解，以及 Docker-Compose 工具的使用。 如果你有 Kubernetes 相关经验，推荐使用后续的 Kubernetes 部署方式。 与容器相关的官方资源有： Skywalking-Docker Skywalking-Kubernetes Docker-Compose 快速部署 拉取部署包, 以 8.1.0 版本为例： $ git clone git@github.com:apache/skywalking-docker.git $ cd skywalking-docker/8/8.1.0/compose/ $ docker-compose up -d 部署完成之后你可以访问 http://localhost:8080 访问 UI。 容器运行 Skywalking-OAP 同样的，你也可以分开单独运行，以 8.1.0 版本为例，和前面通过脚本部署一样，OAP 默认使用 H2 存储。 $ docker run --name oap --restart always -d apache/skywalking-oap-server:8.1.0 如果你需要选择 Elasticsearch 存储，你可以通过环境变量进行配置： $ docker run --name oap --restart always -d -e SW_STORAGE=elasticsearch -e SW_STORAGE_ES_CLUSTER_NODES=elasticsearch:9200 apache/skywalking-oap-server:8.1.0-es6 更过环境变量配置可以参考 Skywalking-Docker 文档：https://github.com/apache/skywalking-docker/blob/master/8.x/8.1.0/oap/README.md#configuration 容器运行 Skywalking-RocketBot-UI 以 8.1.0 版本为例，这里假设 OAP Server 的地址就是 oap:12800. $ docker run --name oap --restart always -d -e SW_OAP_ADDRESS=oap:12800 apache/skywalking-ui:8.1.0 部署完成之后你可以访问 http://localhost:8080 访问 UI。 更多配置可以参考：https://github.com/apache/skywalking-docker/blob/master/8/8.0/ui/README.md#configuration 通过 Kubernetes 平台部署 目前推荐使用 helm-chart 部署，你也可以将其转换为原生的 Kubernetes 编排文件。 拉取部署包, 以 8.1.0 版本为例： $ git clone git@github.com:apache/skywalking-kubernetes.git $ git checkout v3.1.0 $ cd skywalking-kubernetes/chart/skywalking $ helm dep up skywalking # 可选操作，根据自身需求进行配置更改 $ vim values.yml # 也可以通过如下方式进行参数覆盖。 # 这里推荐将 Elasticsearch 和 Skywalking 分开部署。不建议使用 Skywalking Helm Chart 自含的 ES 安装方式。 $ helm install skywalking -n \\ --set elasticsearch.enabled=false \\ --set elasticsearch.config.host= \\ --set elasticsearch.config.port.http= \\ --set elasticsearch.config.user= \\ --set elasticsearch.config.password= \\ 更多详细的操作可以参考：https://github.com/apache/skywalking-kubernetes Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"installation/configuration/":{"url":"installation/configuration/","title":"参数解释以及集群模式部署","keywords":"","body":"配置详解以及高级特性 核心配置详解 ······ core: selector: ${SW_CORE:default} default: # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate # Receiver: Receive agent data, Level 1 aggregate # Aggregator: Level 2 aggregate # 后端集群角色配置，默认 Mixed 代表 Receiver 和 Aggregator 角色共存。 # 当我们的微服务规模较大的时候，可以通过调整 Receiver 和 Aggregator 集群来指责分离，提高 OAP 集群接收数据的效率。 role: ${SW_CORE_ROLE:Mixed} restHost: ${SW_CORE_REST_HOST:0.0.0.0} restPort: ${SW_CORE_REST_PORT:12800} restContextPath: ${SW_CORE_REST_CONTEXT_PATH:/} gRPCHost: ${SW_CORE_GRPC_HOST:0.0.0.0} gRPCPort: ${SW_CORE_GRPC_PORT:11800} gRPCSslEnabled: ${SW_CORE_GRPC_SSL_ENABLED:false} gRPCSslKeyPath: ${SW_CORE_GRPC_SSL_KEY_PATH:\"\"} gRPCSslCertChainPath: ${SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:\"\"} gRPCSslTrustedCAPath: ${SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:\"\"} downsampling: - Hour - Day - Month # 此处是关于数据清理策略的相关配置 enableDataKeeperExecutor: ${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true} # Turn it off then automatically metrics data delete will be close. dataKeeperExecutePeriod: ${SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5} # How often the data keeper executor runs periodically, unit is minute # Trace、Database 语句等记录的数据的保存周期，单位：天 recordDataTTL: ${SW_CORE_RECORD_DATA_TTL:3} # Unit is day # P50、P90等类似的聚合指标数据的保存周期，单位：天 metricsDataTTL: ${SW_CORE_RECORD_DATA_TTL:7} # Unit is day # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute, # the metrics may not be accurate within that minute. enableDatabaseSession: ${SW_CORE_ENABLE_DATABASE_SESSION:true} # 定时上报 TOP_N Database 语句的时间周期，默认每 10 分钟上报一次。可以根据实时要求调整时间周期短一些。 topNReportPeriod: ${SW_CORE_TOPN_REPORT_PERIOD:10} # top_n record worker report cycle, unit is minute # Extra model column are the column defined by in the codes, These columns of model are not required logically in aggregation or further query, # and it will cause more load for memory, network of OAP and storage. # But, being activated, user could see the name in the storage entities, which make users easier to use 3rd party tool, such as Kibana->ES, to query the data by themselves. activeExtraModelColumns: ${SW_CORE_ACTIVE_EXTRA_MODEL_COLUMNS:false} # The max length of service + instance names should be less than 200 serviceNameMaxLength: ${SW_SERVICE_NAME_MAX_LENGTH:70} instanceNameMaxLength: ${SW_INSTANCE_NAME_MAX_LENGTH:70} # The max length of service + endpoint names should be less than 240 endpointNameMaxLength: ${SW_ENDPOINT_NAME_MAX_LENGTH:150} ······· OAP 存储配置 ······ storage: # 可通过该选择起选择后端存储，默认 H2 selector: ${SW_STORAGE:h2} elasticsearch: # Skywalking 默认不支持多租户/多环境/多项目概念的。多套 Skywalking 的时候为了实现数据隔离，可以通过该参数生成带前缀的索引名。 nameSpace: ${SW_NAMESPACE:\"\"} clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200} # 配置 elasticsearch 的链接协议。HTTP/HTTPS protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"} trustStorePath: ${SW_STORAGE_ES_SSL_JKS_PATH:\"\"} trustStorePass: ${SW_STORAGE_ES_SSL_JKS_PASS:\"\"} # elasticsearch 用户名 user: ${SW_ES_USER:\"\"} # elasticsearch 用户密码 password: ${SW_ES_PASSWORD:\"\"} # elasticsearch 密钥文件所在路径 secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool. dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index. # 索引主分片数量 indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:1} # The index shards number is for store metrics data rather than basic segment record superDatasetIndexShardsFactor: ${SW_STORAGE_ES_SUPER_DATASET_INDEX_SHARDS_FACTOR:5} # Super data set has been defined in the codes, such as trace segments. This factor provides more shards for the super data set, shards number = indexShardsNumber * superDatasetIndexShardsFactor. Also, this factor effects Zipkin and Jaeger traces. # 索引副分片数量 indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html # elasticsearch 批量写入时的写入数量。可根据 elasticsearch 集群规模进行调整。 bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests # elasticsearch 批量写入的时间间隔，且无论是否达到上面批量写入的数量阈值。 flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests # 查询 elasticsearch 的时候，返回的数据条目最大数量。这里使用了 elasticsearch 默认最大值 10000 resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000} metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000} segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200} profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200} # elasticsearch 索引级别的高级配置. # 比如 translog 配置：`advanced: ${SW_STORAGE_ES_ADVANCED:\"{\\\"index.translog.durability\\\":\\\"request\\\",\\\"index.translog.sync_interval\\\":\\\"5s\\\"}\"}` # 更多请参考：https://www.elastic.co/guide/en/elasticsearch/reference/7.4/index-modules-translog.html advanced: ${SW_STORAGE_ES_ADVANCED:\"\"} elasticsearch7: nameSpace: ${SW_NAMESPACE:\"\"} clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200} protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"http\"} trustStorePath: ${SW_STORAGE_ES_SSL_JKS_PATH:\"\"} trustStorePass: ${SW_STORAGE_ES_SSL_JKS_PASS:\"\"} dayStep: ${SW_STORAGE_DAY_STEP:1} # Represent the number of days in the one minute/hour/day index. user: ${SW_ES_USER:\"\"} password: ${SW_ES_PASSWORD:\"\"} secretsManagementFile: ${SW_ES_SECRETS_MANAGEMENT_FILE:\"\"} # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool. indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:1} # The index shards number is for store metrics data rather than basic segment record superDatasetIndexShardsFactor: ${SW_STORAGE_ES_SUPER_DATASET_INDEX_SHARDS_FACTOR:5} # Super data set has been defined in the codes, such as trace segments. This factor provides more shards for the super data set, shards number = indexShardsNumber * superDatasetIndexShardsFactor. Also, this factor effects Zipkin and Jaeger traces. indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:1000} # Execute the bulk every 1000 requests flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000} metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000} segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200} profileTaskQueryMaxSize: ${SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200} advanced: ${SW_STORAGE_ES_ADVANCED:\"\"} h2: driver: ${SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource} url: ${SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db} user: ${SW_STORAGE_H2_USER:sa} metadataQueryMaxSize: ${SW_STORAGE_H2_QUERY_MAX_SIZE:5000} mysql: properties: jdbcUrl: ${SW_JDBC_URL:\"jdbc:mysql://localhost:3306/swtest\"} dataSource.user: ${SW_DATA_SOURCE_USER:root} dataSource.password: ${SW_DATA_SOURCE_PASSWORD:root@1234} dataSource.cachePrepStmts: ${SW_DATA_SOURCE_CACHE_PREP_STMTS:true} dataSource.prepStmtCacheSize: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250} dataSource.prepStmtCacheSqlLimit: ${SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048} dataSource.useServerPrepStmts: ${SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true} metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000} influxdb: # InfluxDB configuration url: ${SW_STORAGE_INFLUXDB_URL:http://localhost:8086} user: ${SW_STORAGE_INFLUXDB_USER:root} password: ${SW_STORAGE_INFLUXDB_PASSWORD:} database: ${SW_STORAGE_INFLUXDB_DATABASE:skywalking} actions: ${SW_STORAGE_INFLUXDB_ACTIONS:1000} # the number of actions to collect duration: ${SW_STORAGE_INFLUXDB_DURATION:1000} # the time to wait at most (milliseconds) fetchTaskLogMaxSize: ${SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000} # the max number of fetch task log in a request ······ Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"sniffer/":{"url":"sniffer/","title":"探针接入","keywords":"","body":"探针接入 前置条件 Skywalking OAP后端收集器器已经安装部署好，假设暴露的地址为: localhost:11800 步骤 获取探针 安装探针 启动时配置相关参数 获取探针 不同版本下载地址: http://skywalking.apache.org/downloads/ 此处以 8.1.0 为例: 首先点击右边地址下载 Skywalking 安装包，⾥面包含了探针 Agent 压缩包:https://www-us.apache.org/dist/skywalking/8.1.0/apache-skywalking-apm-8.1.0.tar.gz;也可以查看该⽂档同级⽬目录下的压缩包。 或者在Linux系统中执⾏行行如下命令: 下载压缩包 $ wget https://www-us.apache.org/dist/skywalking/6.4.0/apache-skywalking-apm-8.1.0.tar.gz 解压缩之后 $ tar -zxvf apache-skywalking-apm-8.1.0.tar.gz +-- agent +-- activations apm-toolkit-log4j-1.x-activation.jar apm-toolkit-log4j-2.x-activation.jar apm-toolkit-logback-1.x-activation.jar ... +-- config agent.config +-- plugins apm-dubbo-plugin.jar apm-feign-default-http-9.x.jar apm-httpClient-4.x-plugin.jar ..... +-- optional-plugins apm-gson-2.x-plugin.jar ..... +-- bootstrap-plugins jdk-http-plugin.jar ..... +-- logs skywalking-agent.jar 安装探针 主要分为两种情况: 如果你的业务服务通过war包部署 Linux Tomcat 7, Tomcat 8 需要在 tomcat/bin/catalina.sh 添加如下配置: CATALINA_OPTS=\"$CATALINA_OPTS -javaagent:/path/to/skywalking-agent/skywalking- agent.jar\"; export CATALINA_OPTS Windows Tomcat 7, Tomcat 8 需要在 tomcat/bin/catalina.sh 添加如下配置: set \"CATALINA_OPTS=-javaagent:/path/to/skywalking-agent/skywalking-agent.jar\" 另外，关于war包容器器化, 需要将 tomcat/bin/catalina.sh 更改后重新打包或者挂载至 Docker 镜像。 catalina.sh 文件: ······ # SkyWalking Configuration CATALINA_OPTS=\"$CATALINA_OPTS -javaagent:/skywalking-agent/skywalking-agent.jar\"; export CATALINA_OPTS ······· Dockerfile: FROM tomcat:7.0.94-jre7 ENV TZ=Asia/Shanghai \\ DIST_NAME=query-service \\ AGENT_REPO_URL=\"http://nexus.mschina.io/nexus/service/local/repositories/labs/ content/io/daocloud/mircoservice/skywalking/agent/2.0.1/agent-2.0.1.gz\" ADD $AGENT_REPO_URL / RUN set -ex; \\ tar -zxf /agent-2.0.1.gz; \\ rm -rf agent-2.0.1.gz; RUN ln -sf /usr/share/zoneinfo/$TZ /etc/localtime \\ && echo $TZ > /etc/timezone ADD catalina.sh /usr/local/tomcat/bin/ ADD target/struts-spring-demo.war /usr/local/tomcat/webapps/ WORKDIR /usr/local/tomcat/webapps/ CMD [\"catalina.sh\",\"run\"] 如果你的业务服务通过Jar包部署: $ java -javaagent:/path/to/skywalking-agent/skywalking-agent.jar -jar yourApp.jar 【推荐】通过 Kubernetes Sidecar 方式接⼊： 这种方式则将探针单独的打包成了一个镜像，通过 initContainers 和业务容器共享⽂件夹，以此加载探针。 # refs: https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-initialization/ spec: initContainers: - name: sidecar image: your-skywalking-agent-sidecar:6.4.0 # 容器镜像，包含静态资源文件 imagePullPolicy: IfNotPresent command: [\"cp\", \"-r\", \"/data/agent\", \"/sidecar\"] volumeMounts: - name: sidecar mountPath: /sidecar containers: - name: apm-item image: your-business-apm-demo imagePullPolicy: IfNotPresent env: - name: JAVA_OPTS value: \"-javaagent:/sidecar/agent/skywalking-agent.jar\" - name: SW_AGENT_NAME value: apm-demo - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES value: oap:11800 ports: - name: http containerPort: 8082 volumeMounts: - name: sidecar mountPath: /sidecar volumes: - name: sidecar #共享agent文件夹 emptyDir: {} restartPolicy: Always 启动时配置相关参数 前面安装好探针之后，我们需要配置探针将数据发送到后端的地址。⼀般推荐通过环境变量参数传入配置值: SW_AGENT_NAME : 探针名字, 一般和业务服务名一致 SW_AGENT_COLLECTOR_BACKEND_SERVICES: 后端收集器器地址。默认为 127.0.0.1:11800 . 更多参数可以参考 agent/config/agent.config 文件。或者可以浏览官方配置说明：https://github.com/apache/skywalking/blob/master/docs/en/setup/service-agent/java-agent/README.md 参考文档: Skywalking Agent 探针接入 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"sniffer/agent_param.html":{"url":"sniffer/agent_param.html","title":"探针参数配置","keywords":"","body":"探针参数配置 以下内容详细解释了agent/config/agent.config配置文件中的参数： 配置Key 描述 默认值 例如 agent.namespace 默认设置为空字符\"\"。命名空间，可通过此参数实现隔离。具体效果则是共用同一套Es，并在索引Index前面带上前缀。命名空间隔离跨进程传播中的标头。HEADER名称将组合成： HeaderName:Namespace. Not set agent.namespace=Team-A agent.service_name 在 DMP 链路追踪 UI 中展示的应用名，与 Eureka 中注册的应用名一致（在接入了 Eureka 的情况下）。 Your_ApplicationName agent.application_code=Demo-App agent.sample_n_per_3_secs 默认全部。每3秒采样的数量。设置为负数代表全样采取。 Not set agent.sample_n_per_3_secs=-1 agent.authentication 默认未设置。认证token，与后端application.yml中的设置保持一致。 Not set agent.authentication = dangrous agent.span_limit_per_segment 默认未设置。在单个segment中最大的span数量，通过此设置，可以节省应用内存成本。 Not set agent.span_limit_per_segment=300 agent.ignore_suffix 默认未设置。忽略追踪过程中包含了此前缀的segment。 Not set agent.ignore_suffix=.jpg,.jpeg,.js,.css,.png,.bmp,.gif,.ico,.mp3,.mp4,.html,.svg agent.is_open_debugging_class 默认为false。如果设置为true的话，探针会在 /debugging 目录中生成所有被增强的class文件。 Not set agent.is_open_debugging_class = true agent.active_v2_header 默认激活V2版本。 true agent.active_v1_header 默认关闭V1版本。 false collector.grpc_channel_check_interval grpc通道状态检测间隔时间。 30 collector.grpc_channel_check_interval=40 collector.backend_service 默认为127.0.0.1:10800。后端Collector收集器的地址，通过逗号分割集群地址。 127.0.0.1:11800 logging.level 默认为DEBUG。探针日志级别设置。 DEBUG INFO logging.file_name 日志文件名称。 skywalking-api.log logging.file_name=skywalking-collector.log logging.dir 日志文件目录名称。默认使用system.out输出日志。 \"\" logging.max_file_size 日志文件大小最大值。如果日志超出此阈值，将会切分到新的日志文件中。 300 * 1024 * 1024 jvm.buffer_size 收集Jvm信息的缓存大小。 60 * 10 buffer.channel_size Channel缓冲大小。 5 buffer.buffer_size 缓冲大小。 300 plugin.elasticsearch.trace_dsl **默认关闭**,如果打开，将追踪Elasticsearch中的DSL语句。 false Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"sniffer/trace_ingore.html":{"url":"sniffer/trace_ingore.html","title":"端点过滤-忽略追踪","keywords":"","body":"自定义忽略指定端点（Trace Path/Endpoint） 此方式作为一个可选插件来帮助我们忽略指定的Trace，比如常见的Eureka心跳信息等。 此方式作为一个可选插件来帮助我们忽略指定的Trace，比如常见的Eureka心跳信息等。 前置条件 获取到Skywalking探针的压缩包或者探针的镜像（此处采用的方式）。解压过后的目录结构如下： +-- agent +-- activations apm-toolkit-log4j-1.x-activation.jar apm-toolkit-log4j-2.x-activation.jar apm-toolkit-logback-1.x-activation.jar ... +-- config agent.config +-- plugins apm-dubbo-plugin.jar apm-feign-default-http-9.x.jar apm-httpClient-4.x-plugin.jar ..... +-- optional-plugins apm-spring-annotation-plugin.jar apm-trace-ignore-plugin.jar ➊ skywalking-agent.jar 由于是可选插件，因此，默认情况下并没有激活，我们需要将➊中的jar包拷贝或剪切到上面的plugins目录下并添加相关配置来激活该插件,即： +-- agent +-- activations apm-toolkit-log4j-1.x-activation.jar apm-toolkit-log4j-2.x-activation.jar apm-toolkit-logback-1.x-activation.jar ... +-- config agent.config +-- plugins apm-dubbo-plugin.jar apm-feign-default-http-9.x.jar apm-httpClient-4.x-plugin.jar apm-trace-ignore-plugin.jar ➊ 注意此处所在文件夹为plugins。 ..... +-- optional-plugins apm-spring-annotation-plugin.jar skywalking-agent.jar 在config目录下创建apm-trace-ignore-plugin.config文件并添加如下配置激活插件： trace.ignore_path=/your/path/1/**,/your/path/2/** ➊ ➊ 中的路径配置规则支持Ant Path匹配风格，比如： /path/*, /path/**, /path/?。匹配的Path路径将不会被记录。 基于容器Sidecar的方式接入的最佳实践 主要讲解在Kubernetes Pod initContainer 中执行Shell指令，将 apm-trace-ignore-plugin.jar 插件拷贝至 plugins 文件夹，并配置需要忽略的路径。 apiVersion: apps/v1 kind: Deployment metadata: namespace: dmp-ns1 name: daoshop-user-center labels: app: daoshop-user-center spec: selector: matchLabels: app: daoshop-user-center template: metadata: labels: app: daoshop-user-center spec: # refs: https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-initialization/ initContainers: - name: dx-monitor-agent-sidecar image: registry.dx.io/daocloud-dmp/dx-monitor-agent-sidecar:release-2.3.0-0b0cbd1 imagePullPolicy: IfNotPresent command: - \"sh\" - \"-c\" - > mv /sidecar/skywalking/agent/optional-plugins/apm-trace-ignore-plugin-6.5.0-SNAPSHOT.jar /sidecar/skywalking/agent/plugins; ➊ echo 'trace.ignore_path=${TRACE_IGNORE_PATH:/eureka/**,/api/sail/**}' >> /sidecar/skywalking/agent/config/apm-trace-ignore-plugin.config; ➋ cp -r /sidecar /target; volumeMounts: - name: sidecar mountPath: /target containers: - image: {{ daoshop-user-center.image }} name: daoshop-user-center resources: requests: memory: \"2048Mi\" cpu: \"500m\" limits: memory: \"2048Mi\" cpu: \"500m\" ports: - containerPort: 18081 env: - name: JAVA_OPTS value: \"-javaagent:/sidecar/sidecar/skywalking/agent/skywalking-agent.jar\" - name: SW_AGENT_NAME value: apm-demo - name: SW_AGENT_COLLECTOR_BACKEND_SERVICES value: dx-skywalking-oap-ng.dx-pilot.svc:11800 volumeMounts: - name: sidecar mountPath: /sidecar volumes: - name: sidecar #共享agent文件夹 emptyDir: {} --- apiVersion: v1 kind: Service metadata: name: daoshop-user-center spec: type: NodePort ports: - port: 18081 selector: app: daoshop-user-center ➊ 将trace-ignore插件拷贝至plugins目录下。 ➋ 添加相关配置,这里将忽略追踪 /api/sail/** 为前缀的URL。 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"sniffer/customize-enhance-trace.html":{"url":"sniffer/customize-enhance-trace.html","title":"支持自定义方法/函数增强","keywords":"","body":"支持自定义方法/函数增强 本节主要展示如何通过探针以及配置追踪到方法级别。 主要分为两种方式： 手动在Java Method中加入 @Trace 注解. 通过 apm-customize-enhance-plugin 插件配置需要追踪的方法名. 手动在Java Method中加入 @Trace 注解 使用maven或gradle引入toolkit依赖。 org.apache.skywalking apm-toolkit-trace ${skywalking.version} 使用 TraceContext.traceId() API 得到 traceId 代码示例： import TraceContext; ... modelAndView.addObject(\"traceId\", TraceContext.traceId()); 在你想追踪的方法上添加@Trace注解。添加后，你就可以在方法调用栈中查看到span的信息。 在被追踪的方法的上下文周期内添加自定义tag。 ActiveSpan.error() 将当前 Span 标记为出错状态. ActiveSpan.error(String errorMsg) 将当前 Span 标记为出错状态, 并带上错误信息. ActiveSpan.error(Throwable throwable) 将当前 Span 标记为出错状态, 并带上 Throwable. ActiveSpan.debug(String debugMsg) 在当前 Span 添加一个 debug 级别的日志信息. ActiveSpan.info(String infoMsg) 在当前 Span 添加一个 info 级别的日志信息. 例如： ActiveSpan.tag(\"my_tag\", \"my_value\"); ActiveSpan.error(); ActiveSpan.error(\"Test-Error-Reason\"); ActiveSpan.error(new RuntimeException(\"Test-Error-Throwable\")); ActiveSpan.info(\"Test-Info-Msg\"); ActiveSpan.debug(\"Test-debug-Msg\"); 通过 apm-customize-enhance-plugin 插件配置需要追踪的方法名 实现对类的自定义增强需要2步: 激活插件，将插件从 optional-plugins/apm-customize-enhance-plugin.jar 移动到 plugin/apm-customize-enhance-plugin.jar. 在 agent.config 中配置 plugin.customize.enhance_file，指明增强规则文件，比如 /absolute/path/to/customize_enhance.xml. 例如下customize_enhance.xml 配置： arg[0] arg[1] arg[3].[0] arg[2].['k1'] arg[4].[1] arg[4].[2] arg[0] arg[0] arg[1] arg[0].id arg[0].model1.name arg[0].model1.getId() arg[0].os.[1] arg[0].getM().['k1'] arg[0] arg[1] arg[0].[0] arg[0].[0] arg[1] 上述文件中的配置说明： | 配置 | 说明 | |:----------------- |:---------------| | class_name | 要被增强的类 | | method | 类的拦截器方法 | | operation_name | 如果进行了配置，将用它替代默认的operation_name | | operation_name\\_suffix | 表示在operation_name后添加动态数据 | | static | 方法是否为静态方法 | | tag | 将在local span中添加一个tag。key的值需要在XML节点上表示。| | log | 将在local span中添加一个log。key的值需要在XML节点上表示。| | arg[x] | 表示输入的参数值。比如args[0]表示第一个参数。 | | .[x] | 当正在被解析的对象是Array或List，你可以用这个表达式得到对应index上的对象。| | .['key'] | 当正在被解析的对象是Map, 你可以用这个表达式得到map的key。| Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"alarm/":{"url":"alarm/","title":"告警模块","keywords":"","body":"告警模块 Skywalking 发送告警的基本原理是每隔一段时间轮询 skywalking-oap 收集到的链路追踪的数据，再根据所配置的告警规则（如服务响应时间、服务响应时间百分比）等，如果达到阈值则发送响应的告警信息。 发送告警信息是以线程池异步的方式调用 webhook 接口完成，（具体的webhook接口可以使用者自行定义），从而开发者可以在指定的webhook接口中自行编写各种告警方式，钉钉告警、邮件告警等等。 告警的核心由一组规则驱动，这些规则定义在 安装解压缩包里面的config/alarm-settings.yml文件中, 打开之后如下所示：rules 即为需要配置的告警规则的列表；第一个规则 'endpoint_percent_rule'，是规则名，不能重复且必须以 '_rule' 为结尾. rules: # Rule unique name, must be ended with `_rule`.（告警规则名称应该具有唯一性，且必须以 `_rule` 结尾。） endpoint_percent_rule: # Metrics value need to be long, double or int. （指标值需要是long，double 或者 int） metrics-name: endpoint_percent threshold: 75 op: 告警规则的定义分为两部分。 告警规则。它们定义了应该如何触发度量警报，应该考虑什么条件。 网络钩子。当警告触发时，哪些服务终端需要被告知，你可以通过钩子接收告警信息，然后按需将告警信息推送到其他告警平台。 告警规则 告警规则主要有以下几点： Rule name。在告警信息中显示的唯一名称。必须以_rule结尾。指定的规则（与规则名不同，这里是对应的告警中的规则map，具体可查看 backend-alarm.md，其中一些常见的，endpoint_percent_rule——端点相应半分比告警，service_percent_rule——服务相应百分比告警） Metrics name。 也是 OAL 脚本中的度量名。只支持long,double和int类型。详情见所有可能的度量名称列表. Include names。使用本规则告警的服务列表。比如服务名，端点名。 Threshold。阈值,与metrics-name和下面的比较符号相匹配 OP。 操作符, 支持 >, , =。欢迎贡献所有的操作符。如 metrics-name: endpoint_percent, threshold: 75，op: Period.。多久告警规则需要被核实一下。这是一个时间窗口，与后端部署环境时间相匹配。 Count。 在一个Period窗口中，如果values超过Threshold值（按op），达到Count值，需要发送警报。 Silence period。在时间N中触发报警后，在TN -> TN + period这个阶段不告警。 默认情况下，它和Period一样，这意味着相同的告警（在同一个Metrics name拥有相同的Id）在同一个Period内只会触发一次。 默认告警规则 为了方便，我们在发行版中提供了默认的alarm setting.yml文件，包括以下规则 1.过去3分钟内服务平均响应时间超过1秒。 1.服务成功率在过去2分钟内低于80%。 1.服务90%响应时间在过去3分钟内低于1000毫秒. 1.服务实例在过去2分钟内的平均响应时间超过1秒。 1.端点平均响应时间过去2分钟超过1秒。 所有可能的度量名称列表 这些度量名称定义在 OAL 脚本中, 现在，来自Service, Service Instance, Endpoint的度量可以用于告警，我们会在后期版本中进行扩展。 Webhook SkyWalking 的告警 Webhook 要求接收方是一个 Web 容器。 需要在部署启动的时候在 config/alarm-settings.yml文件中配置接受请求的URL： # Sample alarm rules. rules: service_resp_time_rule: metrics-name: service_resp_time # [Optional] Default, match all services in this metrics（可选项，默认匹配所有服务） include-names: - dubbox-provider - dubbox-consumer threshold: 1000 op: \">\" period: 10 count: 1 &#x1F447; 配置webhook，接收告警规则的URL。 webhooks: - http://127.0.0.1:8090/notify/ - http://127.0.0.1:8888/go-wechat/ 告警的消息会通过 HTTP 请求进行发送, 请求方法为 POST, Content-Type 为 application/json, JSON 格式可以参考 List, 包含以下信息. scopeId，scope. 所有可用的 Scope 请查阅 org.apache.skywalking.oap.server.core.source.DefaultScopeDefine. name. 目标 Scope 的实体名称. id0. Scope 实体的 ID. id1. 未使用. ruleName. 触发的告警规则名称. alarmMessage. 报警消息内容. startTime. 告警时间. 以下是一个 POST 方式推送出去的告警信息样例： [{ \"scopeId\": 1, \"scope\": \"SERVICE\", \"name\": \"serviceA\", \"id0\": 12, \"id1\": 0, \"ruleName\": \"service_resp_time_rule\", \"alarmMessage\": \"alarmMessage xxxx\", \"startTime\": 1560524171000 }, { \"scopeId\": 1, \"scope\": \"SERVICE\", \"name\": \"serviceB\", \"id0\": 23, \"id1\": 0, \"ruleName\": \"service_resp_time_rule\", \"alarmMessage\": \"alarmMessage yyy\", \"startTime\": 1560524171000 }] 以下是一个可参考的告警配置： # Sample alarm rules. rules: # Rule unique name, must be ended with `_rule`. service_resp_time_rule: metrics-name: service_resp_time op: \">\" threshold: 500 period: 10 count: 1 silence-period: 5 message: Response time of service {name} is more than 1000ms in last 10 minutes. service_sla_rule: # Indicator value need to be long, double or int metrics-name: service_sla op: \"\" threshold: 500 period: 10 count: 1 silence-period: 5 message: 90% response time of service {name} is lower than 1000ms in last 10 minutes service_instance_resp_time_rule: metrics-name: service_instance_resp_time op: \">\" threshold: 500 period: 10 count: 1 silence-period: 5 message: Response time of service instance {name} is more than 1000ms in last 10 minutes. endpoint_avg_rule: metrics-name: endpoint_avg op: \">\" threshold: 500 period: 10 count: 1 silence-period: 5 message: Response time of endpoint {name} is more than 1000ms in last 10 minutes. webhooks: # - http://127.0.0.1/notify/ # - http://127.0.0.1/go-wechat/ Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"extensions/":{"url":"extensions/","title":"使用扩展","keywords":"","body":"扩展使用 TraceId与日志组件集成 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"extensions/self_telementry.html":{"url":"extensions/self_telementry.html","title":"Skywalking 自监控","keywords":"","body":"Skywalking 自监控 为了能够接收 Prometheus 相关的指标数据，Skywalking 新增了 Prometheus Fetcher 的插件。 同时，基于该插件，Skywalking 也可以将自身 Skywalking OAP Server 的指标接收并进行监控。 其中包括了 CPU、内存、GC 消耗时间、数据持久化的延时以及延时热力图等指标。 8.x 版本中，当我们部署完 Skywalking OAP Server 之后，Skywalking UI 提供了默认的指标监控面板。 我们可以对默认的面板进行调整，以此满足对 Skywalking 自监控的需求： //TODO： 面板调整 Skywalking 默认提供了常见的监控指标，如果我们还需要其他更多的指标信息，可以在 oap-server/server-bootstrap/src/main/resources/fetcher-prom-rules/self.yml中进行自定义配置： ...... fetcherInterval: PT15S fetcherTimeout: PT10S metricsPath: /metrics staticConfig: # targets will be labeled as \"instance\" targets: - localhost:1234 labels: service: oap-server metricsRules: - name: instance_cpu_percentage scope: SERVICE_INSTANCE operation: avg sources: process_cpu_seconds_total: counterFunction: RATE range: PT1M scale: 2 relabel: service: - service instance: - instance - name: instance_jvm_memory_bytes_used scope: SERVICE_INSTANCE operation: avg sources: jvm_memory_bytes_used: relabel: service: - service instance: - instance ...... Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"extensions/es_https/":{"url":"extensions/es_https/","title":"Skywalking HTTPS 认证连接 Elasticsearch","keywords":"","body":"Skywalking 通过 HTTPS SSL 认证连接 Elasticsearch 证书准备 需要注意的是，目前 ElasticSearch 支持的证书类型有: jceks、jks、dks、pkcs11、pkcs12. 如果证书类型不在上面类型中，可以通过keytool工具进行转换 例如将一个 密码为changeit的ca.pem 格式的证书转换为jks格式的证书，将其命名为es_keystore.jks: keytool -import -v -trustcacerts -file ca.pem -keystore es_keystore.jks -keypass changeit -storepass changeit 更改Skywalking 中 application.yml关于ES的配置： 将protocol协议更改为https 配置keyStorePath和keyStorePass 注意clusterNodes配置中Elasticsearch连接的端口 storage: elasticsearch: # nameSpace: ${SW_NAMESPACE:\"\"} user: ${SW_ES_USER:\"\"} # User needs to be set when Http Basic authentication is enabled password: ${SW_ES_PASSWORD:\"\"} # Password to be set when Http Basic authentication is enabled clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:443} keyStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:\"../es_keystore.jks\"} keyStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:\"changeit\"} protocol: ${SW_STORAGE_ES_HTTP_PROTOCOL:\"https\"} indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2} indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0} # Those data TTL settings will override the same settings in core module. recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:2000} # Execute the bulk every 2000 requests bulkSize: ${SW_STORAGE_ES_BULK_SIZE:20} # flush the bulk every 20mb flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"extensions/log/log.html":{"url":"extensions/log/log.html","title":"TraceId与日志组件集成","keywords":"","body":"TraceId与日志组件集成 通过 Skywalking 提供的工具包，我们可以将 Skywalking 在追踪过程中生成的 TraceId 唯一标识集成到我们业务应用中常见的日志组件 logback、log4j。其中 lo4j 支持 1.x 和 2.x 版本。 本章节参考源码在Github 最终效果： 2018-07-25 17:44:58.842 [TID:N/A] [main] INFO o.s.b.c.e.t.TomcatEmbeddedServletContainer -Tomcat started on port(s): 8001 (http) 2018-07-25 17:44:58.852 [TID:N/A] [main] INFO i.d.n.s.l.AgentLog4jDemoApplication -Started AgentLog4jDemoApplication in 4.03 seconds (JVM running for 12.204) 2018-07-25 17:45:10.226 [TID:39.58.15325119102050001] [http-nio-8001-exec-1] INFO o.a.c.c.C.[Tomcat].[localhost].[/] -Initializing Spring FrameworkServlet 'dispatcherServlet' 2018-07-25 17:45:10.226 [TID:39.58.15325119102050001] [http-nio-8001-exec-1] INFO o.s.web.servlet.DispatcherServlet -FrameworkServlet 'dispatcherServlet': initialization started 2018-07-25 17:45:10.247 [TID:39.58.15325119102050001] [http-nio-8001-exec-1] INFO o.s.web.servlet.DispatcherServlet -FrameworkServlet 'dispatcherServlet': initialization completed in 21 ms 2018-07-25 17:45:10.314 [TID:39.58.15325119102050001] [http-nio-8001-exec-1] INFO i.d.n.sw.log4j.HelloWorldController -words:demo 步骤一 此处以logback工具包为例，在你的业务项目中，使用 Maven 或者 Gradle 导入相应的依赖工具包： Maven 在pom.xml文件中添加如下依赖。 org.apache.skywalking apm-toolkit-logback-1.x ${skywalking.version} 7.0.0--> Gradle 在build.gradle中配置如下依赖： dependencies { ······ compile 'org.apache.skywalking:apm-toolkit-logback-1.x:6.2.0' ······ } 步骤二 需要对你的日志组件配置文件中添加如下配置： ...... %d{yyyy-MM-dd HH:mm:ss.SSS} [%tid] [%thread] %-5level %logger{36} -%msg%n ...... 最终运行你的应用/服务 使用 -javaagent 参数激活 Skywalking 的探针, 如果当前上下文中存在 traceid，logback 将输出 traceId。否则将输出 TID: N/A. Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"extensions/nginx_grpc/nginx-grpc.html":{"url":"extensions/nginx_grpc/nginx-grpc.html","title":"使用 Nginx 代理 gRPC，为 Skywalking 集群提供负载均衡","keywords":"","body":"Nginx 代理gRPC—为 Skywalking 提供负载均衡 Apache Skywalking 是一款优秀的分布式链路追踪系统以及 APM 系统，但在社区的实现中，并没有着重考虑客户端负载的问题。因为社区已经有很多对 gRPC 的代理的成熟方案（Skywalking 中 Agent 探针与后端主要通过 gRPC 方式通信）。 因此，为了实现 Skywalking OAP 负载均衡，需要自己做一层反向代理。 2018年3月17日，NGINIX 官方宣布在 nginx 1.13.10中将会支持 gRPC，这一宣告表示了 NGINX 已完成对 gRPC 的原生支持。众所周知，gRPC 已经是新一代微服务的事实标准RPC框架。对于实现来说，可以用服务框架等手段来做到负载均衡，但业界其实还没有非常成熟的针对gRPC的反向代理软件。 NGINIX 作为老牌负载均衡软件对 gRPC 进行了支持，之前已经可以代理 gRPC 的 TCP 连接，新版本之后，还可以终止、检查和跟踪 gRPC 的方法调用： 发布 gRPC 服务，然后使用 NGINX 应用 HTTP/2 TLS 加密、速率限制、基于 IP 的访问控制列表和日志记录； 通过单个端点发布多个 gRPC 服务，使用 NGINX 检查并跟踪每个内部服务的调用； 使用 Round Robin, Least Connections 或其他方法在集群分配调用，对 gRPC 服务集群进行负载均衡； 使用 NGINX 代理 gRPC 服务 在客户端和服务器应用程序之间插入 NGINX，为服务器应用程序提供了一个稳定可靠的网关。 使用 Docker 容器搭建 NGINX Server 使用 Nginx 官方提供的docker image搭建server： $ docker pull nginx:1.13.10 1.13.10: Pulling from library/nginx 2a72cbf407d6: Pull complete fefa2faca81f: Pull complete 080aeede8114: Pull complete Digest: sha256:c4ee0ecb376636258447e1d8effb56c09c75fe7acf756bf7c13efadf38aa0aca Status: Downloaded newer image for nginx:1.13.10 Nginx gRPC 配置 Nginx 使用 HTTP 服务器监听 gRPC 流量，并使用 grpc_pass 指令代理流量。 为 Nginx 创建以下代理配置，在端口 80 上侦听未加密的 gRPC 流量并将请求转发到端口31320上的服务器： grpc_proxy.conf文件: upstream grpcservers { server 10.15.160.1:31320; # Skywalking OAP 后端 11800 地址 } server { listen 80 http2; location / { grpc_pass grpc://grpcservers; error_page 502 = /error502grpc; } location = /error502grpc { internal; default_type application/grpc; add_header grpc-status 14; add_header grpc-message \"unavailable\"; return 204; } } 启动 Nginx 容器 docker run --name mynginx4grpc -p 80:80 -v tmp4myworkspace:/etc/nginx/conf.d:ro -d nginx:1.17 其中，上述 Nginx 配置文件位于 tmp4myworkspace 目录下。 参考 Module ngx_http_grpc_module Service Mesh利器：NGINX+gRPC Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"extensions/es_opti.html":{"url":"extensions/es_opti.html","title":"Elasticsearch 优化","keywords":"","body":"Elasticsearch 优化实践 Elasticsearch（简称ES）是一个基于Apache Lucene(TM)的开源搜索引擎。无论在开源还是专有领域，Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。 Elasticsearch 作为开源首选的分布式搜索分析引擎，通过一套系统轻松满足用户的日志实时分析、全文检索、结构化数据分析等多种需求，大幅降低大数据时代挖掘数据价值的成本。 但是，Lucene只是一个库。想要使用它，你必须使用Java来作为开发语言并将其直接集成到你的应用中，更糟糕的是，Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。 Elasticsearch 也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 不过，Elasticsearch 不仅仅是Lucene和全文搜索，还能这样去描述它： 分布式的实时文件存储，每个字段都被索引并可被搜索 分布式的实时分析搜索引擎 可以扩展到上百台服务器，处理PB级结构化或非结构化数据 而且，所有的这些功能被集成到一个服务里面，你的应用可以通过简单的RESTful API、各种语言的客户端甚至命令行与之交互。 上手ES非常容易。它提供了许多合理的缺省值，并对初学者隐藏了复杂的搜索引擎理论。它开箱即用（安装即可使用），只需很少的学习既可在生产环境中使用。 Elasticsearch 在 Apache 2 license 下许可使用，可以免费下载、使用和修改。 以下是 ElasticSearch 中几个常用的概念： Cluster（集群）：ES可以运行一个独立的实例提供搜索服务。不过，为了处理大型数据集，实现容错和高可用性，ES可以运行在一群服务器上。这些服务器的集合称为集群。 Node（节点）：组成集群的每一台机器称之为一个节点。 Index（索引）：在Elasticsearch中存储数据的行为就叫做索引(indexing)。一个索引(index)就像是传统关系数据库中的数据库，它是相关文档存储的地方，index的复数是indices 或indexes。 Shard（分片）：当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片。每个分片放到不同的服务器上。 当你查询的索引分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即这个过程对用户来说是透明的。 Replica（副本）：为提高查询吞吐量或实现高可用性，可以使用分片副本。 副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。 当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片。 一 集群配置 1 操作系统配置优化 禁用 swap，一旦发生内存交换，肯定会带来巨大的性能问题。在 ElasticSearch 的高效读写需求下，不允许使用交换内存。 sed -i '/swap/s/^/#/' /etc/fstab swapoff -a 提高最大打开文件数限制和最大用户进程数 echo \"* - nofile 65536\" >> /etc/security/limits.conf echo \"* - nproc 131072\" >> /etc/security/limits.conf Elasticsearch 对各种文件混合使用了 NioFs 和 MMapFs 。确保配置最大映射数量，以便有足够的虚拟内存可用于 mmapped 文件。 echo \"vm.max_map_count = 262144\" >> /etc/sysctl.conf sysctl -p 2 节点个数 ES内部维护集群通信，不是基于zookeeper的分发部署机制，所以，无需奇数。 但是discovery.zen.minimum_master_nodes的值要设置为：候选主节点的个数/2+1，才能有效避免脑裂。 3 磁盘性能 Elasticsearch最大的瓶颈往往是磁盘读写性能，尤其是随机读取性能。使用SSD（PCI-E接口SSD卡/SATA接口SSD盘）通常比机械硬盘（SATA盘/SAS盘）查询速度快5~10倍. 二 ES 开启高性能写模式 现象 Skywalking 日志出现 429 Too many requests 造成原因 因为接入Skywalking 的实例太多，导致Skywalking 在Bulk（批量）写入 ES 的时候，ES 性能不够报错。 综合来说,提升写入速度从以下几方面入手: 加大 translog flush ,目的是降低 iops,writeblock 加大 index refresh间隔, 目的除了降低 io, 更重要的降低了 segment merge 频率 调整 bulk 线程池和队列 优化磁盘间的任务均匀情况,将 shard 尽量均匀分布到物理主机的各磁盘 优化节点间的任务分布,将任务尽量均匀的发到各节点 优化 lucene 层建立索引的过程,目的是降低 CPU 占用率及 IO 针对Skywalking，提炼出如下优化参数，在elasticsearch.yml文件中新增后重启 ElasticSearch 生效： # 锁定物理内存地址，防止elasticsearch内存被交换出去,也就是避免es使用swap交换分区，https://www.elastic.co/guide/en/elasticsearch/reference/7.4/setup-configuration-memory.html bootstrap.memory_lock: true # 增大队列大小，建立索引的过程偏计算密集型任务,应该使用固定大小的线程池配置,来不及处理的放入队列,线程数量配置为 CPU 核心数+1,避免过多的上下文切换.队列大小可以适当增加. thread_pool.index.queue_size: 1000 thread_pool.write.queue_size: 1000 Elasticsearch近实时的本质是：最快1s写入的数据可以被查询到。 如果refresh_interval设置为1s，势必会产生大量的segment，检索性能会受到影响。 所以，非实时的场景可以调大，设置为30s，甚至-1。 三 设置合理的磁盘限额水位线 为了保护节点数据安全ES 会定时(cluster.info.update.interval，默认 30 秒)检查一下各节点的数据目录磁盘使用情况。根据单个分片的数据大小，合理调整 watermark.low 的值。如果单个分片数据大小超过磁盘空间的 10%，建议将 watermark.low 调整到 70% 。同样的，对于大量的小分片可以调高 watermark.low 来提高磁盘的使用率，降低成本。 cluster.routing.allocation.disk.threshold_enabled 默认true, 启用磁盘空间阈值检查 cluster.routing.allocation.disk.watermark.low 默认85%, 分片不会分配(除新建的索引的主分片不受影响) cluster.routing.allocation.disk.watermark.high 默认90%, 达到该值,ES会做relocate,影响所有分片 cluster.routing.allocation.disk.watermark.flood_stage 默认95%, index.blocks.read_only_allow_delete,当磁 当磁盘空间水位线超过 95%会导致索引只读。需要通过下面的参数取消只读的状态。 PUT _all/_settings { \"index\": { \"blocks\": { \"read_only_allow_delete\": \"false\" } } } 四 删除索引的副本分片 在测试环境中，往往对数据并没有很高的可用性要求，但是对 ElasticSearch 的性能有一定的要求。副本分片在一定程度上会占用 ElasticSearch 的堆内存资源，并且在集群重启时，索引的恢复耗时也会受副本分片的影响。因此，在测试环境，可以将索引的副本分片设置为 0。 ES_HOST=10.15.120.16; curl -sSL \"http://$ES_HOST:9200/_cat/shards?v\"|awk '{if($3==\"r\") print $1}'|sort|uniq|xargs -I {} echo \"curl -sSL -XPUT http://$ES_HOST:9200/{}/_settings -d '{\\\"index\\\":{\\\"number_of_replicas\\\":0}}' -H 'Content-Type: application/json'\" > delete_replicas.sh # 检查 delete_replicas.sh 文件中的索引名称，防止误删数据，确认无误后执行脚本 bash ./delete_replicas.sh // TODO: 待补充 Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "},"faq/":{"url":"faq/","title":"FAQ","keywords":"","body":"FAQ Copyright © Jared Tan 2019-2020 all right reserved，powered by GitbookUpdated: 2020-08-18 15:43:17 "}}